# 春招秋招面试总结
## 1. 快手风控NLP（二面挂）：  

一面：  
1.讲一下项目，介绍一下域对抗网络，谣言检测，图神经网络。  
2.比赛前三名怎么做的，有哪些不足。  
3.bert怎么用的（huggingface 训练好的），bert变种有没有了解？  
4.self-attention，multihead-attention有什么作用  
5.BN和LN，BN在训练和测试的时候是怎么样的  
6.label smoothing，解决过拟合的方法，dropout讲一下  
7.平时怎么找论文
8. 士兵，墙，空地，BFS从士兵开始搜，得到最近距离  

二面：  
1.讲一下比赛，GNN介绍一下，还有哪些应用  
2.MSE和交叉熵的区别  
3.label smoothing,干净的数据和有噪声的数据哪个用它好一点？  
4.A,B符合uniform(0,1),求max（A,B)期望  
5.给定一个函数接口，能判断是大还是小，写出算法，试出这个数  

## 2. 快手MMU（一面挂）  
一面：  
1.讲一下比赛项目，介绍自己  
2.VGG用的几层的，怎么用的  
3.bert怎么用的，怎么训练的（答：bertservingclient，说比较慢）  
4.pytorch 保存加载模型  
5.L1，L2正则化  
6.机器学习会不会，sklearn会不会，读过什么通过比赛发表的论文？  
7.有序数组还原平衡二叉树

## 3. 阿里钉钉电话面（挂）
1.谣言检测，哪一些方法，最近的一篇论文  
2.F1-score 精确率 召回率  
3.比赛举办方，比赛背景，比赛的方法  
4.三种新闻，真实新闻，虚假新闻，无需判断的区别
5.label smoothing  
6.分布式的机器学习框架  
7.机器学习 LR RF XGB
8.正则化了l1,l2,那个下降的速度快  
9.排序的稳定性和不稳定性  

## 4. 百度一面（挂）  
1. 介绍自己  
2. 讲一下bert，bert的输入，bert激活函数，ERNIE了解么  
3. 激活函数有哪些了解么，relu为什么具有非线性  
4. 算法题，旋转数组中target是否存在，全排列

## 京东（hr挂，零售数据智能）
一面：
聊项目，attention 和 self-attention的区别，为什么要用svd  
算法题 第k大（秒了）  

二面：
聊项目，算法题 打家劫舍Ⅰ，Ⅱ  

hr面
1.自我介绍  
2.考研分数  
3.六级 分数不是很高  
4.英语水平：英文文档阅读无压力，口语水平需要加强  
5.哪里人 独生子女 择业城市有考虑么（没有明确打算，走一步看一步，倾向留北京）  
6.看实习生的机会是怎么考虑的（京东给我offer，很愿意，考虑转正）  
7.对于即将到来的机会，职业目标怎么规划的（考虑在nlp方向继续深造，深入了解，深入该领域） 其他？（没有考虑）  
8.学科是什么（信息与通信工程）  
9.为什么要做算法（算法比较有意思，能够）  
10.课余期间会干嘛(打球，和朋友出去玩)  
11.项目介绍 印象深刻的一件事（答得不好）  
12.面试官提建议  
13.具体部门，上班时间，薪资  

## 美团 （offer，语音交互部）  
一面：  
1.项目的决策，为何要用cls来作为句子表示  
2.svd的矩阵怎么建立的  
3.讲一下GIN，还有哪些GNN  
4.算法题：A[i]>2A[i-1] 是否存在两个数，和为K  
  
二面：（半小时）  
介绍，项目，排序算法，快排  

## 网易有道(一面过，拒二面）
一面：  
1.项目介绍  
2.lstm和rnn  
3.lr和贝叶斯，决策树和svm，svm核函数  
4.KL散度是什么  
5.算法题 一个数组有正有负，连续子数组的最大乘积。  

# 秋招  

## 网易智企内推（挂）  
一面：  
1.谣言检测实验中代表性的工作  
2.过拟合问题展开讲一下  
3.TextCNN参数  
4.热词主要用什么方法做的
5.yield 的用法  
6.训练效果好，测试效果差为什么：    
![c1147712180ee3d67c771305642f88c](https://user-images.githubusercontent.com/17798012/134643427-e828ab0e-5879-42ef-bc2b-49a044827299.png)  
  
二面：  
1.给你一段短文本和一个词表，不考虑复杂的数据结构，如何实现，（排序，滑动窗口）  
2.微博如果有新用户，你怎么办（没办法）  
3.BERT的结构，attention输出的长度是和Q一样还是和K，V一样  
4.残差连接，跳连  
5.bert加载模型时，如何只加载需要的几层模型  

## 字节（一面挂）：
1.bert参数计算
2.K个一组反转链表
3.crf的损失函数

## 字节抖音电商toB：  
一面：  
1.介绍一下谣言检测，对比baseline结果
2.GIN如何提取特征，GIN训练目标  
3.还知道哪些GNN  
4.训练的时候多少事件，提取用户关系向量的方法还有哪些（word2vec，graph embedding）？  
5.梯度消失，怎么解决，transformer里怎么处理的  
6. 深度学习的非线性是体现在哪里？  
7. relu，sigmoid的区别  
8. l1,l2正则的本质  
9. 目标数据不均衡时，怎么做？
10. 两个有序数组，找第k大  

二面：  
微博话题，如何去匹配相关文本
合并k个有序链表  

## 小米（一面挂）：  
1.DANN，SVD，bert和transformer的位置编码  

## 百度（一面挂）：  
1.怎么调参  
2.GIN同构，异构  

## 字节一面风控：  
1.bert里面的mask机制怎么操作的  
2.attention 对比rnn的优势，代价  
3.神经网络的可解释行  
4.正则怎么加？  
5.ln,bn,rnn常用的是那种正则？  
6.54张牌均分成3堆，大小王在同一堆的概率？17/53  
7.https://leetcode-cn.com/problems/contiguous-array/  
